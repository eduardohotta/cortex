# üß† CORTEX - AI Interview Assistant

**CORTEX** (Interview Insight) √© um assistente pessoal alimentado por IA projetado para apoiar profissionais durante entrevistas t√©cnicas e reuni√µes estrat√©gicas em tempo real. Ele combina reconhecimento de voz de √∫ltima gera√ß√£o com modelos de linguagem locais e na nuvem, tudo dentro de uma interface de overlay ultraleve e discreta.

---

## ‚ú® Principais Funcionalidades

### üõ°Ô∏è Modo Stealth (Anti-Print)
- **Janelas Invis√≠veis**: Utiliza transpar√™ncia nativa e prote√ß√£o de conte√∫do para n√£o aparecer em capturas de tela, compartilhamentos de tela (Zoom, Google Meet, Teams) ou grava√ß√µes.
- **Cursor Neutro**: O cursor do mouse n√£o muda de forma ao passar sobre o texto da IA, mantendo a presen√ßa do programa indetect√°vel.

### üéôÔ∏è Transcri√ß√£o em Tempo Real
- **Faster-Whisper Local**: Transcri√ß√£o de alta performance rodando diretamente na sua m√°quina (via Python).
- **Provedores Cloud**: Suporte para Deepgram e Groq para menor lat√™ncia e maior precis√£o quando necess√°rio.
- **Captura Dual**: Capta tanto o seu microfone quanto o √°udio do sistema (entrevistador) via Loopback.

### ü§ñ Intelig√™ncia Artificial (LLM)
- **Modelos Locais**: Integra√ß√£o com `node-llama-cpp` para rodar modelos GGUF (como Llama 3, Qwen) localmente com acelera√ß√£o de GPU.
- **Assistentes Especializados**: Crie e alterne entre perfis (RH, T√©cnico, Lideran√ßa) com prompts de sistema personalizados.
- **Dicion√°rio T√©cnico (Alt+Click)**: Selecione qualquer palavra ou frase no overlay para obter uma defini√ß√£o t√©cnica imediata e contextualizada.

### üñ•Ô∏è Interface Minimalista
- **Floating Remote**: Uma barra de controle flutuante discreta para gerenciar grava√ß√£o, trocar de assistente e disparar o "ASK".
- **Overlay de Resposta**: Exibi√ß√£o de texto em Markdown com suporte a t√≠tulos, listas e blocos de c√≥digo.
- **Dashboard Central**: Interface completa para gerenciar modelos, configura√ß√µes de √°udio e customizar assistentes.

---

## üöÄ Como Come√ßar

### Pr√©-requisitos
- **Node.js**: v18 ou superior.
- **Python**: 3.10+ (necess√°rio para o Whisper local).
- **CABLE Virtual Audio**: Recomendado para captar o √°udio do sistema no Windows.

### Instala√ß√£o

1. Clone o reposit√≥rio:
```bash
git clone https://github.com/seu-usuario/interview-insight.git
cd interview-insight
```

2. Instale as depend√™ncias do Node.js:
```bash
npm install
```

3. Instale as depend√™ncias do Python (para o servi√ßo Whisper):
```bash
pip install faster-whisper numpy sounddevice
```

### Execu√ß√£o

Para iniciar o projeto em modo de desenvolvimento:
```bash
npm run dev
```

Para gerar o build de produ√ß√£o:
```bash
npm run build
```

---

## üõ†Ô∏è Arquitetura T√©cnica

- **Frontend**: React 19 + Vite + TailwindCSS.
- **Backend/Main**: Electron v28.
- **Comunica√ß√£o**: IPC (Inter-Process Communication) para streaming de tokens e logs em tempo real.
- **IA Local**: `node-llama-cpp` (Node binding para llama.cpp).
- **Processamento de √Åudio**: Bridge entre Node.js e Python (spawn pipeline) para o Whisper.

---

## ‚öôÔ∏è Configura√ß√µes Recomendadas

- **Modelos GGUF**: Recomendamos modelos como `Qwen2.5-7B-Instruct` ou `Llama-3-8B` para o melhor equil√≠brio entre velocidade e precis√£o.
- **Acelera√ß√£o**: O projeto detecta automaticamente CUDA (NVIDIA) para acelera√ß√£o de GPU no Whisper e no LLM.

---

## üìú Licen√ßa

Distribu√≠do sob a licen√ßa MIT. Veja `LICENSE` para mais informa√ß√µes.

---

*Desenvolvido com foco em produtividade e excel√™ncia t√©cnica.*
